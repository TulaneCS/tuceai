---
layout: page
title: Research Outcomes
subtitle: TU:CEAI
published: true
---

<p style="text-align:center;"><img src="{{ 'img/tulogo.png' | relative_url }}"/></p>

The Center is pursuing four key directions:

* *Investigating community experiences and perceptions of AI:* To design systems that communities trust, we must first understand existing experiences and perceptions of AI. We will conduct a series of surveys and focus groups to (1) engage and better learn AI experiences and perceptions across demographics (e.g., race, class, gender), particularly with minoritized communities, and (2) consider and integrate modes of feedback, oversight, and interaction toward less or nonbiased AI systems.
* *Investigating new computational methodologies for community-driven AI:* To realize trustworthy AI systems, we will innovate in several fundamental AI areas, including: (1) modeling multi-stakeholder preferences; (2) developing causality-based machine learning models to improve robustness; (3) measuring, mitigating, and tracking bias in AI systems; (4) developing new modes of community-AI interactions to co-create, revise, and monitor the system based on accountability metrics and best practices.
* *Equitable AI for digital health:* With the above innovations, we will investigate human-centered approaches to co-design AI-based digital health applications in two domains: mental health and obesity interventions. Given the socio-economic disparities in the effectiveness of digital health apps, we will design personalized health guidance applications with a focus on algorithmic bias and fairness, providing transparent metrics to measure long-term impacts of interventions by population group.
* *AI for discrimination detection:* We will apply our community-driven AI framework to detect and characterize instances of discrimination by humans in five domains: hiring decisions, housing, credit markets, mental healthcare, and criminal justice proceedings. Advancing on our team's work in audit study field experiments and natural language processing, we will develop new methodologies to detect subtle sources of linguistic discrimination in text data --- for example, loan officers may provide more accurate and helpful advice to non-minority applicants.

