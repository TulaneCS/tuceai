---
layout: page
title: Tulane University Center for Community-Engaged Artificial Intelligence
subtitle: TU:CEAI
published: true
---
<p style="text-align:center;"><img src="{{ 'img/tulogo.png' | relative_url }}"/></p>

Artificial intelligence holds the potential to benefit society in numerous areas, including health, the economy, education, and public safety. However, ensuring that the benefits of AI are shared equitably among society and reducing any potential harmful effects is of critical importance given (i) the concentration of technical capacities into the hands of a few, often highly educated practitioners;  (ii) long-standing socio-technical challenges of algorithmic discrimination, transparency, and accountability that underpin all AI systems; leading to (iii) a pervasive mistrust of AI technology by the public. New Orleans provides evidence of this tension --- early, controversial tech-driven policing programs here were met with grassroots resistance, leading to ordinances restricting surveillance (e.g., facial recognition and predictive policing). Across the country, there is a growing tech backlash concerned that AI may exacerbate existing disparities, widen the digital divide, or otherwise result in a less just society. In response, the scientific community has increasingly prioritized research into socio-technical systems that promote fair and trustworthy AI systems (e.g., NSF's program on Fairness in AI; IBM's AI Fairness 360 Toolkit, etc.).

These trends indicate that AI will succeed only with the trust and support of the communities it affects, especially those from historically underserved groups. The motivating principle of the Center is that this trust must be earned by designing AI systems (1) that are demonstrably fair, transparent, and accountable, (2) that establish meaningful relationships to engage diverse communities in all stages of the AI process, from design through deployment, and (3) that augment, rather than replace, human interaction, i.e., are **human centered**. Achieving this vision requires a transformative approach to AI design. The Center will establish a truly multi-disciplinary team of technologists, designers, social scientists, and community partners for examining and affording new evidence-based socio-technical frameworks to  create and deploy AI systems that are inclusive, effective, fair, transparent, and accountable.
