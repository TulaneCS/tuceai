---
layout: page
title: Tulane University Center for Community-Engaged Artificial Intelligence
subtitle: TU:CEAI
published: true
---
<p style="text-align:center;"><img src="{{ 'img/tulogo.png' | relative_url }}"/></p>

Artificial intelligence holds the potential to benefit society in numerous areas, including health, the economy, education, and public safety. However, ensuring that the benefits of AI are shared equitably among society and reducing any potential harmful effects is of critical importance given (i) the concentration of technical capacities into the hands of a few, often highly educated practitioners;  (ii) long-standing socio-technical challenges of algorithmic discrimination, transparency, and accountability that underpin all AI systems; leading to (iii) a pervasive mistrust of AI technology by the public. New Orleans provides evidence of this tension --- early, controversial tech-driven policing programs here were met with grassroots resistance, leading to ordinances restricting surveillance (e.g., facial recognition and predictive policing). Across the country, there is a growing tech backlash concerned that AI may exacerbate existing disparities, widen the digital divide, or otherwise result in a less just society. In response, the scientific community has increasingly prioritized research into socio-technical systems that promote fair and trustworthy AI systems (e.g., NSF's program on Fairness in AI; IBM's AI Fairness 360 Toolkit, etc.).

These trends indicate that AI will succeed only with the trust and support of the communities it affects, especially those from historically underserved groups. The motivating principle of the Center is that this trust must be earned by designing AI systems (1) that are demonstrably fair, transparent, and accountable, (2) that establish meaningful relationships to engage diverse communities in all stages of the AI process, from design through deployment, and (3) that augment, rather than replace, human interaction, i.e., are **human centered**. Achieving this vision requires a transformative approach to AI design. The Center will establish a truly multi-disciplinary team of technologists, designers, social scientists, and community partners for examining and affording new evidence-based socio-technical frameworks to  create and deploy AI systems that are inclusive, effective, fair, transparent, and accountable, serving as an accelerator for four key  projects:

* *Investigating community experiences and perceptions of AI:* To design systems that communities trust, we must first understand existing experiences and perceptions of AI. We will conduct a series of surveys and focus groups to (1) engage and better learn AI experiences and perceptions across demographics (e.g., race, class, gender), particularly with minoritized communities, and (2) consider and integrate modes of feedback, oversight, and interaction toward less or nonbiased AI systems.
* *Investigating new computational methodologies for community-driven AI:* To realize trustworthy AI systems, we will innovate in several fundamental AI areas, including: (1) modeling multi-stakeholder preferences; (2) developing causality-based machine learning models to improve robustness; (3) measuring, mitigating, and tracking bias in AI systems; (4) developing new modes of community-AI interactions to co-create, revise, and monitor the system based on accountability metrics and best practices.
* *Equitable AI for digital health:* With the above innovations, we will investigate human-centered approaches to co-design AI-based digital health applications in two domains: mental health and obesity interventions. Given the socio-economic disparities in the effectiveness of digital health apps, we will design personalized health guidance applications with a focus on algorithmic bias and fairness, providing transparent metrics to measure long-term impacts of interventions by population group.
* *AI for discrimination detection:* We will apply our community-driven AI framework to detect and characterize instances of discrimination by humans in five domains: hiring decisions, housing, credit markets, mental healthcare, and criminal justice proceedings. Advancing on our team's work in audit study field experiments and natural language processing, we will develop new methodologies to detect subtle sources of linguistic discrimination in text data --- for example, loan officers may provide more accurate and helpful advice to non-minority applicants.

To address this diverse set of pressing AI applications, we have assembled a team of experts in each area, with a diversity of scholarly perspectives on the role of technology in society. The organizing thrust will be to identify common, key issues in AI that span domains and to develop novel human-centered, community-engaged, socio-technical approaches with broad applicability. With this team, the Center will pursue several funding opportunities recently created to support this line of research at NSF, NIH, and other agencies.

The Center requests \$150k per year to coordinate and grow current research programs to ensure external competitiveness via (a) research assistants to pilot interdisciplinary  projects; (b) faculty time to lead research and grant writing; (c) workshops for team building and community outreach; and (d) user studies and other data collection in support of Center projects.
